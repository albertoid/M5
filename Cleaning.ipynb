{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning M5 Forecasting - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.10 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "#Use Python 3.6\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm import tqdm as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal=pd.read_csv('a/calendar.csv')\n",
    "df_sat=pd.read_csv('a/sales_train_validation.csv')\n",
    "df_sam=pd.read_csv('a/sample_submission.csv')\n",
    "df_sep=pd.read_csv('a/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Steps of Cleaning\n",
    "\n",
    "1. Extraction of days from sales_train_validation\n",
    "2. Creation of dummies calendar with event's types, weekdays, months, snaps and wm_yr_wk (will remove later)\n",
    "3. Creation of series for prices depending the week (wm_yr_wk)\n",
    "4. Remove all wm_yr_wk\n",
    "5. Integration of all the products/store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 1919)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File Structure\n",
    "\n",
    "This file has the double of registers of products/stores due to the the first half is dedicated to the validation registers corresponding to the days 1 to 28 of preduction (days 1914 to 1941) corresponding to the validation sample, and the second part corresponding to the evaluation are the days 29 to 56 (days 1942 to 1969)\n",
    "\n",
    "index | id | F1 | F2 | ... | F28\n",
    "----- | -- | -- | -- | --- | ---\n",
    "0  | HOBBIES_1_001_CA_1_validation | Yv0(F1) | Yv0(F2) | ... | Yv0(F28)\n",
    "1  | HOBBIES_1_002_CA_1_validation | Yv1(F1) | Yv1(F2) | ... | Yv1(F28)\n",
    "...\n",
    "30489 | FOODS_3_827_WI_3_validation | Yv30489(F1) | Yv30489(F2) | ... | Yv30489(F28)\n",
    "30490 | HOBBIES_1_001_CA_1_evaluation | Ye0(F1) | Ye0(F2) | ... | Ye0(F28)\n",
    "30491 | HOBBIES_1_001_CA_1_evaluation | Ye1(F1) | Ye1(F2) | ... | Ye1(F28)\n",
    "... \n",
    "60979 | FOODS_3_827_WI_3_evaluation | Ye30489(F1) | Ye30489(F2) | ... | Ye30489(F28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat_d=df_sat.drop(columns=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "def day_data(item_index,fillval=None): #item index of product/store\n",
    "    #Extraccion de dia(s) y transposición\n",
    "    df_sell=df_sat_d.iloc[item_index].T\n",
    "    df_sell.reset_index(drop=True,inplace=True,name='day_sell')\n",
    "    \n",
    "    #Completar la serie para igualar el numero de registros de dias\n",
    "    for i in range(56):\n",
    "        df_sell=df_sell.append(pd.Series([fillval]))\n",
    "    \n",
    "    return df_sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calendario dummies\n",
    "df_cal.month=df_cal.month.apply(lambda x:str(x))\n",
    "df_cal_dum=pd.get_dummies(df_cal[['event_type_1','event_type_2','weekday','month','snap_CA','snap_TX','snap_WI','wm_yr_wk']])\n",
    "\n",
    "def add_cal(df_sell, df_data=df_cal_dum.copy()):\n",
    "    #Integracion de las ventas al Set de datos\n",
    "    df_data['day_sell']=df_sell.values\n",
    "    #Cambio de tipo de datos\n",
    "    df_data.day_sell=df_data.day_sell.apply(lambda x: int(x) if x!= None else None)\n",
    "    return (df_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para el calculo de wm_yr_wk\n",
    "#Regresa indice del rango de los dias de la semana wm_yr_wk de la semana dada\n",
    "\n",
    "def range_days_week(wm_yr_wk):\n",
    "    dn=list(df_cal.wm_yr_wk.unique()).index(wm_yr_wk)*7\n",
    "    return dn, dn+7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de Serie de precios de venta segun semana Walmart\n",
    "\n",
    "def sell_price_series(item_index, df_data, no_value=None):\n",
    "    #Temporal variable for the query who has the item and store in the prices table\n",
    "    temp = df_sep[(df_sep.store_id==df_sat['store_id'].iloc[item_index])&(df_sep.item_id==df_sat['item_id'].iloc[item_index])]\n",
    "    \n",
    "    #Create Clean Series\n",
    "    series_length=1969\n",
    "    output = pd.Series(list( no_value for i in range(series_length)))\n",
    "    \n",
    "    #Write the prices in the intervals corresponding every week who has values\n",
    "    \n",
    "    for i in range(len(temp.wm_yr_wk.unique())):\n",
    "        output.iloc[range_days_week(temp.wm_yr_wk.unique()[i])[0]:range_days_week(temp.wm_yr_wk.unique()[i])[1]]=\\\n",
    "        temp.sell_price[temp.wm_yr_wk==temp.wm_yr_wk.unique()[i]].values[0]\n",
    "        \n",
    "    df_data['sell_price']=output.values\n",
    "    \n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wm_yr_wk(df_data):\n",
    "    df_data = df_data.drop(columns=['wm_yr_wk'])\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(i):\n",
    "#def data_cleaning(nprod=len(df_sat)):\n",
    "    #list_df_sell = []\n",
    "    #for i in tqdm(range(nprod)):\n",
    "    df_sell = day_data(i) #Step 1\n",
    "    df_data = add_cal(df_sell) # Step 2\n",
    "    df_data = sell_price_series(i,df_data) #Step 3\n",
    "    df_data = remove_wm_yr_wk(df_data) #Step 4\n",
    "    #list_df_sell.append(df_data) #Step 5\n",
    "    #return list_df_sell\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.2 s, sys: 12.6 s, total: 50.8 s\n",
      "Wall time: 2h 14min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nprod=len(df_sat)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "list_df_sell = pool.map(data_cleaning,[i for i in range(nprod)])\n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the clean data\n",
    "\n",
    "import pickle\n",
    "pickle_file=open('list_df_sell.pickle','wb')\n",
    "pickle.dump(list_df_sell,pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30490"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Set for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilidades\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "#Modelos\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import BayesianRidge as BR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import AdaBoostRegressor as ABR\n",
    "from sklearn.ensemble import BaggingRegressor as BaR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.ensemble import StackingRegressor as SR\n",
    "from sklearn.ensemble import VotingRegressor as VR\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor as HGBR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df_data.drop(columns=['day_sell'])[:1912], df_data.day_sell[:1912]\n",
    "X_train, X_test, y_train, y_test = TTS(X,y, test_size = 0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578757556443264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr=RFR()\n",
    "rfr.fit(X_train,y_train)\n",
    "y_pred=rfr.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799307717714824"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br=BR()\n",
    "br.fit(X_train,y_train)\n",
    "y_pred=br.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1431077748767045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr=DTR()\n",
    "dtr.fit(X_train,y_train)\n",
    "y_pred=dtr.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850245763618101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr=ABR()\n",
    "abr.fit(X_train,y_train)\n",
    "y_pred=abr.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000630169610951"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar=BaR()\n",
    "bar.fit(X_train,y_train)\n",
    "y_pred=bar.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811524125823093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar=BaR()\n",
    "bar.fit(X_train,y_train)\n",
    "y_pred=bar.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801007145867064"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr=GBR()\n",
    "gbr.fit(X_train,y_train)\n",
    "y_pred=gbr.predict(X_test)\n",
    "MSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n",
      "Warning: Your H2O cluster version is too old (10 months and 19 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>14 hours 17 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Mexico_City</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>10 months and 19 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_al_af72yp</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.997 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.10 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         14 hours 17 mins\n",
       "H2O cluster timezone:       America/Mexico_City\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.3\n",
       "H2O cluster version age:    10 months and 19 days !!!\n",
       "H2O cluster name:           H2O_from_python_al_af72yp\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.997 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.10 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train.copy()\n",
    "train.insert(29,'y_',y_train)\n",
    "test=X_test.copy()\n",
    "test.insert(29,'y_',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = h2o.H2OFrame(train)\n",
    "test = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.columns\n",
    "y='y_'\n",
    "X.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[y]=train[y].asfactor()\n",
    "test[y]=test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml=H2OAutoML(max_models=50, seed=1)\n",
    "aml.train(x=X,y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_9          </td><td style=\"text-align: right;\">              0.803973</td><td style=\"text-align: right;\"> 9.82611 </td><td style=\"text-align: right;\">0.534543</td><td style=\"text-align: right;\">0.285736</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_6          </td><td style=\"text-align: right;\">              0.807997</td><td style=\"text-align: right;\"> 4.49027 </td><td style=\"text-align: right;\">0.48464 </td><td style=\"text-align: right;\">0.234876</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_4          </td><td style=\"text-align: right;\">              0.808469</td><td style=\"text-align: right;\"> 0.456458</td><td style=\"text-align: right;\">0.385047</td><td style=\"text-align: right;\">0.148261</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.811629</td><td style=\"text-align: right;\"> 0.450446</td><td style=\"text-align: right;\">0.38312 </td><td style=\"text-align: right;\">0.146781</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.812755</td><td style=\"text-align: right;\"> 0.449522</td><td style=\"text-align: right;\">0.383289</td><td style=\"text-align: right;\">0.14691 </td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.814053</td><td style=\"text-align: right;\"> 0.457232</td><td style=\"text-align: right;\">0.384917</td><td style=\"text-align: right;\">0.148161</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_5          </td><td style=\"text-align: right;\">              0.815456</td><td style=\"text-align: right;\">10.3385  </td><td style=\"text-align: right;\">0.548498</td><td style=\"text-align: right;\">0.30085 </td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.815595</td><td style=\"text-align: right;\"> 0.476462</td><td style=\"text-align: right;\">0.391142</td><td style=\"text-align: right;\">0.152992</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.816474</td><td style=\"text-align: right;\"> 1.76669 </td><td style=\"text-align: right;\">0.400623</td><td style=\"text-align: right;\">0.160499</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.816474</td><td style=\"text-align: right;\"> 1.76669 </td><td style=\"text-align: right;\">0.400623</td><td style=\"text-align: right;\">0.160499</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_3          </td><td style=\"text-align: right;\">              0.816892</td><td style=\"text-align: right;\"> 0.514772</td><td style=\"text-align: right;\">0.400313</td><td style=\"text-align: right;\">0.16025 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_14         </td><td style=\"text-align: right;\">              0.818915</td><td style=\"text-align: right;\"> 0.448893</td><td style=\"text-align: right;\">0.386564</td><td style=\"text-align: right;\">0.149432</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_9 </td><td style=\"text-align: right;\">              0.819436</td><td style=\"text-align: right;\"> 1.78571 </td><td style=\"text-align: right;\">0.394948</td><td style=\"text-align: right;\">0.155984</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_8          </td><td style=\"text-align: right;\">              0.819478</td><td style=\"text-align: right;\"> 1.68935 </td><td style=\"text-align: right;\">0.815179</td><td style=\"text-align: right;\">0.664517</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_7 </td><td style=\"text-align: right;\">              0.819596</td><td style=\"text-align: right;\"> 2.02969 </td><td style=\"text-align: right;\">0.405257</td><td style=\"text-align: right;\">0.164233</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_4 </td><td style=\"text-align: right;\">              0.819994</td><td style=\"text-align: right;\"> 0.749725</td><td style=\"text-align: right;\">0.397675</td><td style=\"text-align: right;\">0.158145</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200326_104416</td><td style=\"text-align: right;\">              0.821079</td><td style=\"text-align: right;\"> 0.463041</td><td style=\"text-align: right;\">0.377859</td><td style=\"text-align: right;\">0.142777</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20200326_104416                   </td><td style=\"text-align: right;\">              0.821556</td><td style=\"text-align: right;\"> 0.42942 </td><td style=\"text-align: right;\">0.37681 </td><td style=\"text-align: right;\">0.141986</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_13         </td><td style=\"text-align: right;\">              0.822466</td><td style=\"text-align: right;\"> 1.38174 </td><td style=\"text-align: right;\">0.745648</td><td style=\"text-align: right;\">0.555991</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_1 </td><td style=\"text-align: right;\">              0.822509</td><td style=\"text-align: right;\"> 0.864199</td><td style=\"text-align: right;\">0.389257</td><td style=\"text-align: right;\">0.151521</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_1          </td><td style=\"text-align: right;\">              0.823808</td><td style=\"text-align: right;\"> 0.457875</td><td style=\"text-align: right;\">0.378055</td><td style=\"text-align: right;\">0.142926</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200326_104416_model_2      </td><td style=\"text-align: right;\">              0.82632 </td><td style=\"text-align: right;\"> 0.509558</td><td style=\"text-align: right;\">0.406584</td><td style=\"text-align: right;\">0.16531 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_5 </td><td style=\"text-align: right;\">              0.827807</td><td style=\"text-align: right;\"> 0.754219</td><td style=\"text-align: right;\">0.382946</td><td style=\"text-align: right;\">0.146647</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_2 </td><td style=\"text-align: right;\">              0.829696</td><td style=\"text-align: right;\"> 1.49717 </td><td style=\"text-align: right;\">0.398624</td><td style=\"text-align: right;\">0.158901</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200326_104416_model_1      </td><td style=\"text-align: right;\">              0.830303</td><td style=\"text-align: right;\"> 0.514063</td><td style=\"text-align: right;\">0.405682</td><td style=\"text-align: right;\">0.164578</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_10         </td><td style=\"text-align: right;\">              0.831948</td><td style=\"text-align: right;\"> 0.530218</td><td style=\"text-align: right;\">0.409642</td><td style=\"text-align: right;\">0.167807</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_7          </td><td style=\"text-align: right;\">              0.83277 </td><td style=\"text-align: right;\"> 1.13416 </td><td style=\"text-align: right;\">0.6698  </td><td style=\"text-align: right;\">0.448632</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200326_104416   </td><td style=\"text-align: right;\">              0.83303 </td><td style=\"text-align: right;\"> 0.426078</td><td style=\"text-align: right;\">0.370184</td><td style=\"text-align: right;\">0.137036</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_12         </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 0.554141</td><td style=\"text-align: right;\">0.41368 </td><td style=\"text-align: right;\">0.171131</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20200326_104416_model_1          </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 0.576826</td><td style=\"text-align: right;\">0.392798</td><td style=\"text-align: right;\">0.154291</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200326_104416                       </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 0.430827</td><td style=\"text-align: right;\">0.378294</td><td style=\"text-align: right;\">0.143106</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_11         </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 1.24411 </td><td style=\"text-align: right;\">0.705603</td><td style=\"text-align: right;\">0.497875</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200326_104416_model_3      </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 0.630937</td><td style=\"text-align: right;\">0.452384</td><td style=\"text-align: right;\">0.204652</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200326_104416_model_4      </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 1.40886 </td><td style=\"text-align: right;\">0.752281</td><td style=\"text-align: right;\">0.565926</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_6 </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 1.67996 </td><td style=\"text-align: right;\">0.400012</td><td style=\"text-align: right;\">0.16001 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200326_104416_model_2          </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 1.693   </td><td style=\"text-align: right;\">0.815876</td><td style=\"text-align: right;\">0.665654</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20200326_104416                   </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 0.664522</td><td style=\"text-align: right;\">0.471642</td><td style=\"text-align: right;\">0.222446</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_8 </td><td style=\"text-align: right;\">              0.833333</td><td style=\"text-align: right;\"> 2.20044 </td><td style=\"text-align: right;\">0.400281</td><td style=\"text-align: right;\">0.160225</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200326_104416_model_3 </td><td style=\"text-align: right;\">              0.833463</td><td style=\"text-align: right;\"> 1.44211 </td><td style=\"text-align: right;\">0.398092</td><td style=\"text-align: right;\">0.158477</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20200326_104416                   </td><td style=\"text-align: right;\">              0.833723</td><td style=\"text-align: right;\"> 0.666438</td><td style=\"text-align: right;\">0.471578</td><td style=\"text-align: right;\">0.222386</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200326_104416              </td><td style=\"text-align: right;\">              0.834198</td><td style=\"text-align: right;\"> 0.620362</td><td style=\"text-align: right;\">0.385559</td><td style=\"text-align: right;\">0.148656</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb=aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_20200326_104416_model_9\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.25768476128188356\n",
      "RMSE: 0.5076265963105987\n",
      "LogLoss: 8.900116350290968\n",
      "Mean Per-Class Error: 0.7263295036827042\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1062.0</td>\n",
       "<td>108.0</td>\n",
       "<td>50.0</td>\n",
       "<td>23.0</td>\n",
       "<td>38.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1728972</td>\n",
       "<td>222 / 1,284</td></tr>\n",
       "<tr><td>97.0</td>\n",
       "<td>56.0</td>\n",
       "<td>18.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.68</td>\n",
       "<td>119 / 175</td></tr>\n",
       "<tr><td>17.0</td>\n",
       "<td>19.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7358491</td>\n",
       "<td>39 / 53</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7692308</td>\n",
       "<td>10 / 13</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3 / 3</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1 / 1</td></tr>\n",
       "<tr><td>1184.0</td>\n",
       "<td>187.0</td>\n",
       "<td>83.0</td>\n",
       "<td>30.0</td>\n",
       "<td>39.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.2576848</td>\n",
       "<td>394 / 1,529</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1    2    3    4    5    Error     Rate\n",
       "----  ---  ---  ---  ---  ---  --------  -----------\n",
       "1062  108  50   23   38   3    0.172897  222 / 1,284\n",
       "97    56   18   2    0    2    0.68      119 / 175\n",
       "17    19   14   1    1    1    0.735849  39 / 53\n",
       "5     4    1    3    0    0    0.769231  10 / 13\n",
       "2     0    0    1    0    0    1         3 / 3\n",
       "1     0    0    0    0    0    1         1 / 1\n",
       "1184  187  83   30   39   6    0.257685  394 / 1,529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-6 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7423152</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8705036</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.8888162</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.8901243</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.8901243</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.742315\n",
       "2    0.870504\n",
       "3    0.888816\n",
       "4    0.890124\n",
       "5    0.890124\n",
       "6    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.2857360452864149\n",
      "RMSE: 0.5345428376532744\n",
      "LogLoss: 9.82610825718673\n",
      "Mean Per-Class Error: 0.8039729002751397\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1042.0</td>\n",
       "<td>144.0</td>\n",
       "<td>46.0</td>\n",
       "<td>21.0</td>\n",
       "<td>11.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1884735</td>\n",
       "<td>242 / 1,284</td></tr>\n",
       "<tr><td>105.0</td>\n",
       "<td>44.0</td>\n",
       "<td>17.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.7485714</td>\n",
       "<td>131 / 175</td></tr>\n",
       "<tr><td>33.0</td>\n",
       "<td>12.0</td>\n",
       "<td>6.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8867925</td>\n",
       "<td>47 / 53</td></tr>\n",
       "<tr><td>8.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>13 / 13</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3 / 3</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1 / 1</td></tr>\n",
       "<tr><td>1190.0</td>\n",
       "<td>203.0</td>\n",
       "<td>69.0</td>\n",
       "<td>26.0</td>\n",
       "<td>13.0</td>\n",
       "<td>28.0</td>\n",
       "<td>0.2858077</td>\n",
       "<td>437 / 1,529</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1    2    3    4    5    Error     Rate\n",
       "----  ---  ---  ---  ---  ---  --------  -----------\n",
       "1042  144  46   21   11   20   0.188474  242 / 1,284\n",
       "105   44   17   4    1    4    0.748571  131 / 175\n",
       "33    12   6    1    1    0    0.886792  47 / 53\n",
       "8     2    0    0    0    3    1         13 / 13\n",
       "2     0    0    0    0    1    1         3 / 3\n",
       "0     1    0    0    0    0    1         1 / 1\n",
       "1190  203  69   26   13   28   0.285808  437 / 1,529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-6 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7141923</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8613473</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.8737737</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.8750817</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.8763897</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.714192\n",
       "2    0.861347\n",
       "3    0.873774\n",
       "4    0.875082\n",
       "5    0.87639\n",
       "6    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7141734</td>\n",
       "<td>0.0219877</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.6993464</td>\n",
       "<td>0.6862745</td>\n",
       "<td>0.7647059</td>\n",
       "<td>0.6852459</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2858266</td>\n",
       "<td>0.0219877</td>\n",
       "<td>0.2647059</td>\n",
       "<td>0.3006536</td>\n",
       "<td>0.3137255</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.3147541</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>87.4</td>\n",
       "<td>6.6873016</td>\n",
       "<td>81.0</td>\n",
       "<td>92.0</td>\n",
       "<td>96.0</td>\n",
       "<td>72.0</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>9.826792</td>\n",
       "<td>0.7471041</td>\n",
       "<td>9.142705</td>\n",
       "<td>10.289531</td>\n",
       "<td>10.732439</td>\n",
       "<td>8.09806</td>\n",
       "<td>10.871222</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.4289962</td>\n",
       "<td>0.0594794</td>\n",
       "<td>0.3704208</td>\n",
       "<td>0.3644955</td>\n",
       "<td>0.537445</td>\n",
       "<td>0.5255242</td>\n",
       "<td>0.3470952</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.5710038</td>\n",
       "<td>0.0594794</td>\n",
       "<td>0.6295791</td>\n",
       "<td>0.6355045</td>\n",
       "<td>0.462555</td>\n",
       "<td>0.4744758</td>\n",
       "<td>0.6529048</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.285755</td>\n",
       "<td>0.0219434</td>\n",
       "<td>0.2647082</td>\n",
       "<td>0.3006287</td>\n",
       "<td>0.3133900</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.3147541</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1104166</td>\n",
       "<td>0.1177524</td>\n",
       "<td>0.2740894</td>\n",
       "<td>0.2588292</td>\n",
       "<td>-0.0354475</td>\n",
       "<td>0.1927600</td>\n",
       "<td>-0.1381482</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.5337415</td>\n",
       "<td>0.0209172</td>\n",
       "<td>0.514498</td>\n",
       "<td>0.5482961</td>\n",
       "<td>0.5598124</td>\n",
       "<td>0.4850712</td>\n",
       "<td>0.5610295</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.714173  0.0219877  0.735294      0.699346      0.686275      0.764706      0.685246\n",
       "err                      0.285827  0.0219877  0.264706      0.300654      0.313725      0.235294      0.314754\n",
       "err_count                87.4      6.6873     81            92            96            72            96\n",
       "logloss                  9.82679   0.747104   9.1427        10.2895       10.7324       8.09806       10.8712\n",
       "max_per_class_error      1         0          1             1             1             1             1\n",
       "mean_per_class_accuracy  0.428996  0.0594794  0.370421      0.364496      0.537445      0.525524      0.347095\n",
       "mean_per_class_error     0.571004  0.0594794  0.629579      0.635505      0.462555      0.474476      0.652905\n",
       "mse                      0.285755  0.0219434  0.264708      0.300629      0.31339       0.235294      0.314754\n",
       "r2                       0.110417  0.117752   0.274089      0.258829      -0.0354475    0.19276       -0.138148\n",
       "rmse                     0.533741  0.0209172  0.514498      0.548296      0.559812      0.485071      0.561029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.294 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8333333</td>\n",
       "<td>1.7917595</td>\n",
       "<td>0.1602354</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.335 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3818884</td>\n",
       "<td>0.5014432</td>\n",
       "<td>0.1805101</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.375 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.4296791</td>\n",
       "<td>2.7392197</td>\n",
       "<td>0.2132112</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.416 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.4664383</td>\n",
       "<td>5.8668515</td>\n",
       "<td>0.2256377</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.454 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.5926297</td>\n",
       "<td>12.0445253</td>\n",
       "<td>0.3512099</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.491 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.5140282</td>\n",
       "<td>9.1067663</td>\n",
       "<td>0.2642250</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.524 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.4965545</td>\n",
       "<td>8.5161012</td>\n",
       "<td>0.2465664</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2020-03-26 11:20:19</td>\n",
       "<td>17.540 sec</td>\n",
       "<td>32.0</td>\n",
       "<td>0.5076266</td>\n",
       "<td>8.9001164</td>\n",
       "<td>0.2576848</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  -------------------------------\n",
       "    2020-03-26 11:20:19  17.294 sec  0                  0.833333         1.79176             0.160235\n",
       "    2020-03-26 11:20:19  17.335 sec  5                  0.381888         0.501443            0.18051\n",
       "    2020-03-26 11:20:19  17.375 sec  10                 0.429679         2.73922             0.213211\n",
       "    2020-03-26 11:20:19  17.416 sec  15                 0.466438         5.86685             0.225638\n",
       "    2020-03-26 11:20:19  17.454 sec  20                 0.59263          12.0445             0.35121\n",
       "    2020-03-26 11:20:19  17.491 sec  25                 0.514028         9.10677             0.264225\n",
       "    2020-03-26 11:20:19  17.524 sec  30                 0.496555         8.5161              0.246566\n",
       "    2020-03-26 11:20:19  17.540 sec  32                 0.507627         8.90012             0.257685"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>sell_price</td>\n",
       "<td>491.2980042</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2060171</td></tr>\n",
       "<tr><td>month_12</td>\n",
       "<td>256.0709534</td>\n",
       "<td>0.5212131</td>\n",
       "<td>0.1073788</td></tr>\n",
       "<tr><td>weekday_Friday</td>\n",
       "<td>225.7178650</td>\n",
       "<td>0.4594317</td>\n",
       "<td>0.0946508</td></tr>\n",
       "<tr><td>snap_CA</td>\n",
       "<td>137.6281433</td>\n",
       "<td>0.2801317</td>\n",
       "<td>0.0577119</td></tr>\n",
       "<tr><td>snap_WI</td>\n",
       "<td>131.7222748</td>\n",
       "<td>0.2681107</td>\n",
       "<td>0.0552354</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>event_type_1_Religious</td>\n",
       "<td>1.2266078</td>\n",
       "<td>0.0024967</td>\n",
       "<td>0.0005144</td></tr>\n",
       "<tr><td>event_type_1_Cultural</td>\n",
       "<td>0.2263158</td>\n",
       "<td>0.0004606</td>\n",
       "<td>0.0000949</td></tr>\n",
       "<tr><td>event_type_1_Sporting</td>\n",
       "<td>0.1348659</td>\n",
       "<td>0.0002745</td>\n",
       "<td>0.0000566</td></tr>\n",
       "<tr><td>event_type_2_Cultural</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>event_type_2_Religious</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                relative_importance    scaled_importance       percentage\n",
       "----------------------  ---------------------  ----------------------  ----------------------\n",
       "sell_price              491.2980041503906      1.0                     0.2060171065239518\n",
       "month_12                256.0709533691406      0.521213095119261       0.1073788137388634\n",
       "weekday_Friday          225.71786499023438     0.45943167503920934     0.09465078433703039\n",
       "snap_CA                 137.62814331054688     0.2801316963388634      0.057711921525378934\n",
       "snap_WI                 131.72227478027344     0.2681107467718352      0.05523540027790944\n",
       "---                     ---                    ---                     ---\n",
       "event_type_1_Religious  1.2266077995300293     0.002496667580913994    0.0005143562309720554\n",
       "event_type_1_Cultural   0.22631582617759705    0.0004606487798967728   9.490152875812186e-05\n",
       "event_type_1_Sporting   0.1348659098148346     0.00027450937857575943  5.6553627887866035e-05\n",
       "event_type_2_Cultural   0.0                    0.0                     0.0\n",
       "event_type_2_Religious  0.0                    0.0                     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">  p0</th><th style=\"text-align: right;\">  p1</th><th style=\"text-align: right;\">  p2</th><th style=\"text-align: right;\">  p3</th><th style=\"text-align: right;\">  p4</th><th style=\"text-align: right;\">  p5</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=aml.leader.predict(test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Pickle\n",
    "file = open('list_df_sell.pickle', 'rb')\n",
    "list_df_sell = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedataset(i):\n",
    "    Xy=list_df_sell[i].copy()\n",
    "    \n",
    "    #Stracting X_test\n",
    "    X_test=Xy.drop(columns=['day_sell'])[1913:]\n",
    "    \n",
    "    #Remove Nones for all the sample  from X and y in the sell price\n",
    "    Xy.sell_price=Xy.sell_price.astype(float)\n",
    "    Xy=Xy[(Xy.sell_price>0) & (Xy.day_sell >=0)]\n",
    "    \n",
    "    #Prepare X_train and y_train\n",
    "    X_train,y_train = Xy.drop(columns=['day_sell']), Xy.day_sell\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "#from sklearn.linear_model import ElasticNet as EN\n",
    "#from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "def prediction(i, database_size=30490):\n",
    "    \n",
    "    #Xy_train = preparedataset(i)\n",
    "    #X_train = Xy_train[0]\n",
    "    #y_train = Xy_train[1]\n",
    "    \n",
    "    #Applying model\n",
    "\n",
    "    y_pred=xgbmodel(i)\n",
    "\n",
    "\n",
    "    #Write predictions in sumbit validation (first 28)\n",
    "    df_sub.iloc[i,1:] = y_pred[:28]\n",
    "\n",
    "    #Write predictions in submit validation (second 28) row + 30490\n",
    "    df_sub.iloc[i+database_size,1:]=y_pred[28:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641ab3f0f7cc4ea3bf11db763953a3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.46s/it, best loss: 0.7218927072926197]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.84s/it, best loss: 0.7340460215522177]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.31s/it, best loss: 0.743791348184722]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.91s/it, best loss: 0.7113565223530882]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.45s/it, best loss: 0.7166393367156354]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.18s/it, best loss: 0.7214185974742348]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.31s/it, best loss: 0.7207616867916945]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it, best loss: 0.7375261307444854]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.75s/it, best loss: 0.7096242063869472]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it, best loss: 0.727752515088044] \n",
      "100%|██████████| 5/5 [01:47<00:00, 21.43s/it, best loss: 0.7106315747723608]\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.41s/it, best loss: 0.746550646666634] \n",
      "100%|██████████| 5/5 [00:13<00:00,  2.73s/it, best loss: 0.7334479266545756]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.86s/it, best loss: 0.6961002408171493]\n",
      "100%|██████████| 5/5 [00:09<00:00,  2.00s/it, best loss: 0.7088529947863286]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.06s/it, best loss: 0.7234217027821523]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.96s/it, best loss: 0.7449534506762379]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.35s/it, best loss: 0.7074214352283729]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.15s/it, best loss: 0.7110452630995483]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.43s/it, best loss: 0.7208954581352413]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.32s/it, best loss: 0.7397148760346857]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.90s/it, best loss: 0.7170908479865151]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.29s/it, best loss: 0.7204506137432266]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.61s/it, best loss: 0.7279894723333203]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it, best loss: 0.7168386431909406]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.84s/it, best loss: 0.7022138300364046]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.89s/it, best loss: 0.7406555140243226]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.85s/it, best loss: 0.7339730879197254]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.22s/it, best loss: 0.723174898746191] \n",
      "100%|██████████| 5/5 [00:07<00:00,  1.47s/it, best loss: 0.7347105578399863]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.28s/it, best loss: 0.7333335207868251]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.13s/it, best loss: 0.7103095968572429]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.26s/it, best loss: 0.7105464724306929]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.20s/it, best loss: 0.7332807493178806]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.94s/it, best loss: 0.7335589675954457]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.27s/it, best loss: 0.7152092626335607]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.13s/it, best loss: 0.7164728080487691]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.71s/it, best loss: 0.7097293198272048]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.35s/it, best loss: 0.739368573173982] \n",
      "100%|██████████| 5/5 [00:12<00:00,  2.52s/it, best loss: 0.7297290612873748]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.66s/it, best loss: 0.7426697676353332]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.39s/it, best loss: 0.7220798667868463]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.68s/it, best loss: 0.7107560648383273]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.52s/it, best loss: 0.6999003149344255]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.24s/it, best loss: 0.6929649915912506]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it, best loss: 0.7004581511821776]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.53s/it, best loss: 0.7277022055240956]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it, best loss: 0.7259783182486901]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.95s/it, best loss: 0.7088437343130938]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.33s/it, best loss: 0.7303169778425458]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.81s/it, best loss: 0.7217382592670226]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.52s/it, best loss: 0.7167538910449454]\n",
      "100%|██████████| 5/5 [00:19<00:00,  3.80s/it, best loss: 0.7234297064396333]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.62s/it, best loss: 0.7225568465449347]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.85s/it, best loss: 0.7304730646335316]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.94s/it, best loss: 0.7136961569909285]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it, best loss: 0.7429614407486504]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it, best loss: 0.7211383355520373]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.26s/it, best loss: 0.7345612904883212]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.75s/it, best loss: 0.7421499175190008]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.89s/it, best loss: 0.7083777695984531]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it, best loss: 0.7321070697864829]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.16s/it, best loss: 0.7252598523698919]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it, best loss: 0.7234042936513422]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.85s/it, best loss: 0.7091614244171889]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.26s/it, best loss: 0.7450820305946991]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.63s/it, best loss: 0.7143054972108625]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.82s/it, best loss: 0.7401299909463761]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.76s/it, best loss: 0.717026944872053] \n",
      "100%|██████████| 5/5 [00:12<00:00,  2.59s/it, best loss: 0.7078046785538896]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.84s/it, best loss: 0.7149234838054533]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.12s/it, best loss: 0.7286333502067089]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.72s/it, best loss: 0.7288983809306043]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it, best loss: 0.729604649856866]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.79s/it, best loss: 0.7200448330070368]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.12s/it, best loss: 0.7147830357743824]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.43s/it, best loss: 0.7167504646663353]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.60s/it, best loss: 0.7661707321742454]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.89s/it, best loss: 0.7110070145132804]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.99s/it, best loss: 0.7214643683683466]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, best loss: 0.6968408821759189]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.05s/it, best loss: 0.7109601072233411]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.91s/it, best loss: 0.7129895109519145]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.38s/it, best loss: 0.7288095191140742]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.11s/it, best loss: 0.7102567961427884]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.75s/it, best loss: 0.7465935373187349]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.88s/it, best loss: 0.7140631171820585]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.03s/it, best loss: 0.726242726253985] \n",
      "100%|██████████| 5/5 [00:08<00:00,  1.65s/it, best loss: 0.7026410380458998]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.41s/it, best loss: 0.7208242844951953]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it, best loss: 0.734945354645331] \n",
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it, best loss: 0.7304533207005227]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.51s/it, best loss: 0.7236782097066982]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.81s/it, best loss: 0.7361094821237566]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.68s/it, best loss: 0.7131407407947401]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.83s/it, best loss: 0.7572076645937347]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.86s/it, best loss: 0.7117361732513985]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it, best loss: 0.7291708584721899]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.06s/it, best loss: 0.7314599629956342]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.93s/it, best loss: 0.7181893656632717]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.25s/it, best loss: 0.7143239475861296]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.38s/it, best loss: 0.7475660623684643]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.68s/it, best loss: 0.7173013230564539]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.48s/it, best loss: 0.7260339405424516]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.97s/it, best loss: 0.7138547434778292]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.19s/it, best loss: 0.7285407076668158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.79s/it, best loss: 0.7275397655417688]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.14it/s, best loss: 0.7182878632222962]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.83s/it, best loss: 0.7282619708046174]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it, best loss: 0.7103382931390395]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.91s/it, best loss: 0.7212467640117082]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.48s/it, best loss: 0.694003129205088] \n",
      "100%|██████████| 5/5 [00:12<00:00,  2.56s/it, best loss: 0.7320376553952468]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.67s/it, best loss: 0.7266260829075266]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.74s/it, best loss: 0.7414803659940502]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.95s/it, best loss: 0.7266643065214146]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.69s/it, best loss: 0.7267823809116732]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.59s/it, best loss: 0.7403783212418082]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it, best loss: 0.7323266075487735]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.49s/it, best loss: 0.7075803313000445]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it, best loss: 0.7159369769858691]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it, best loss: 0.7273665064247373]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.39s/it, best loss: 0.7218109272514466]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.44s/it, best loss: 0.7183064493567652]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.83s/it, best loss: 0.7230425911377985]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.54s/it, best loss: 0.7304828748699742]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.48s/it, best loss: 0.7106541625220806]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.50s/it, best loss: 0.7396503097297842]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.78s/it, best loss: 0.7422962000821536]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.13s/it, best loss: 0.7192981673722655]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.49s/it, best loss: 0.7383055663179589]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.05s/it, best loss: 0.7302467079533658]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.73s/it, best loss: 0.7325055234112582]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.71s/it, best loss: 0.7192909223571499]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.00s/it, best loss: 0.7169218290598713]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it, best loss: 0.7448975528203656]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.65s/it, best loss: 0.7102576506286962]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.91s/it, best loss: 0.7036405212330913]\n",
      "100%|██████████| 5/5 [00:09<00:00,  2.00s/it, best loss: 0.7295921177139976]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.75s/it, best loss: 0.6945404082963126]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.93s/it, best loss: 0.733277463414415]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.11s/it, best loss: 0.7177752841213153]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.29s/it, best loss: 0.7305681974306819]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.27s/it, best loss: 0.7288567491817867]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it, best loss: 0.7087644810753682]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.10s/it, best loss: 0.7404272706690569]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.31s/it, best loss: 0.7180498644210792]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.23s/it, best loss: 0.7316529317036433]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it, best loss: 0.7451063895367367]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.78s/it, best loss: 0.7217017101473627]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.57s/it, best loss: 0.7175188446511568]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.45s/it, best loss: 0.7274948235838337]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.97s/it, best loss: 0.7251937826577979]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.84s/it, best loss: 0.7191850074871364]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it, best loss: 0.7221252463959948]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.47s/it, best loss: 0.7168312439113893]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.55s/it, best loss: 0.7038878272848529]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.24s/it, best loss: 0.7465096195207758]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it, best loss: 0.7304885475384039]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.65s/it, best loss: 0.7150880374636202]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.88s/it, best loss: 0.7138177953763166]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.88s/it, best loss: 0.7395174376567257]\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.43s/it, best loss: 0.7220522967999375]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it, best loss: 0.71710546490662]  \n",
      "100%|██████████| 5/5 [00:14<00:00,  2.95s/it, best loss: 0.7212755654745826]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s, best loss: 0.7124982271632871]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.29s/it, best loss: 0.7146400837917007]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.71s/it, best loss: 0.7532142993396257]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.24s/it, best loss: 0.7165092404066735]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.96s/it, best loss: 0.7442011745258923]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.31s/it, best loss: 0.7319145881420382]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.05s/it, best loss: 0.7502109752425665]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.30s/it, best loss: 0.7004307031816335]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.68s/it, best loss: 0.7490928115226477]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it, best loss: 0.7192753089547077]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.58s/it, best loss: 0.7023942473969536]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.44s/it, best loss: 0.7209952374797309]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.78s/it, best loss: 0.7213828194876775]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.57s/it, best loss: 0.7356462173190328]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.76s/it, best loss: 0.7310389792578172]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.77s/it, best loss: 0.7308981269506103]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.42s/it, best loss: 0.7211047789577191]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.74s/it, best loss: 0.718683862249755]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.48s/it, best loss: 0.6983773359820219]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.61s/it, best loss: 0.7343034421806283]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it, best loss: 0.7180817541111338]\n",
      "100%|██████████| 5/5 [00:20<00:00,  4.11s/it, best loss: 0.7512708535770506]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.04s/it, best loss: 0.7238582070161845]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.27s/it, best loss: 0.7229487554007341]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.07s/it, best loss: 0.7243963134791566]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, best loss: 0.7438847647062867]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.01s/it, best loss: 0.7337862034698024]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.40s/it, best loss: 0.7204421877978575]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.46s/it, best loss: 0.7047918126235795]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.87s/it, best loss: 0.7192936849251722]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.82s/it, best loss: 0.7362090772045394]\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.47s/it, best loss: 0.7101063074888392]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.78s/it, best loss: 0.7191701574211234]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.89s/it, best loss: 0.6953416383196411]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.28s/it, best loss: 0.7312811483045555]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.68s/it, best loss: 0.7199989745036771]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.83s/it, best loss: 0.7308996977914731]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.55s/it, best loss: 0.7003186400797583]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.51s/it, best loss: 0.7199761309350567]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.17s/it, best loss: 0.7209854789111834]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.84s/it, best loss: 0.723152168529324] \n",
      "100%|██████████| 5/5 [00:14<00:00,  2.82s/it, best loss: 0.7253446048503503]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.98s/it, best loss: 0.7363815112951272]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.78s/it, best loss: 0.7331482886879465]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.46s/it, best loss: 0.7162538758481322]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.60s/it, best loss: 0.7200332743859725]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.82s/it, best loss: 0.7309337027150629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.02s/it, best loss: 0.7084177503941711]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.56s/it, best loss: 0.7215235114028374]\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.50s/it, best loss: 0.7332446114062335]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.83s/it, best loss: 0.7297436837489365]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.44s/it, best loss: 0.7135440383809222]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it, best loss: 0.7162996722594076]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.47s/it, best loss: 0.7185448078819516]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it, best loss: 0.7448790966832042]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.57s/it, best loss: 0.7127714182885775]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.47s/it, best loss: 0.7184971523351087]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.41s/it, best loss: 0.7200850821890901]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.40s/it, best loss: 0.7498428863268112]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.54s/it, best loss: 0.7499021727544897]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it, best loss: 0.7126365582758396]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.61s/it, best loss: 0.71077269069429]  \n",
      "100%|██████████| 5/5 [00:15<00:00,  3.14s/it, best loss: 0.7214349992917358]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.59s/it, best loss: 0.7230872294317142]\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.79s/it, best loss: 0.7160413013076586]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.85s/it, best loss: 0.7071781924464042]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.61s/it, best loss: 0.7331245570322757]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.28s/it, best loss: 0.7275117072624548]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.34s/it, best loss: 0.7254664612025226]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.54s/it, best loss: 0.7096093401454413]\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.41s/it, best loss: 0.743513865556407] \n",
      "100%|██████████| 5/5 [00:10<00:00,  2.02s/it, best loss: 0.7029999915155312]\n",
      " 60%|██████    | 3/5 [00:09<00:06,  3.02s/it, best loss: 0.7301692123199888]"
     ]
    }
   ],
   "source": [
    "#Copy to the sample (df_sam) = submit (df_sub)\n",
    "df_sub=df_sam.copy()\n",
    "\n",
    "#for i in tqdm(range(10)):\n",
    "for i in tqdm(range(len(df_sat))):\n",
    "    prediction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('M5_AV_05_XGBoost_n5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30490</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.060448</td>\n",
       "      <td>0.710953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223788</td>\n",
       "      <td>0.228602</td>\n",
       "      <td>0.168158</td>\n",
       "      <td>0.214708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130675</td>\n",
       "      <td>0.381387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>1.003537</td>\n",
       "      <td>0.753696</td>\n",
       "      <td>2.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30491</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.278447</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.378045</td>\n",
       "      <td>0.432572</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567867</td>\n",
       "      <td>0.794892</td>\n",
       "      <td>0.420917</td>\n",
       "      <td>0.188256</td>\n",
       "      <td>0.244426</td>\n",
       "      <td>1.325752</td>\n",
       "      <td>0.162870</td>\n",
       "      <td>0.247418</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.623214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30492</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.454166</td>\n",
       "      <td>0.229238</td>\n",
       "      <td>0.252124</td>\n",
       "      <td>0.273253</td>\n",
       "      <td>0.193736</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>1.498980</td>\n",
       "      <td>0.229238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384402</td>\n",
       "      <td>1.239972</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.289158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.473690</td>\n",
       "      <td>0.520014</td>\n",
       "      <td>0.222852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30493</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>2.097975</td>\n",
       "      <td>1.589313</td>\n",
       "      <td>0.978691</td>\n",
       "      <td>0.857186</td>\n",
       "      <td>1.933128</td>\n",
       "      <td>3.185360</td>\n",
       "      <td>3.249015</td>\n",
       "      <td>1.696931</td>\n",
       "      <td>1.589313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.364504</td>\n",
       "      <td>0.672822</td>\n",
       "      <td>2.513978</td>\n",
       "      <td>1.846013</td>\n",
       "      <td>1.789156</td>\n",
       "      <td>1.431149</td>\n",
       "      <td>1.015532</td>\n",
       "      <td>1.690391</td>\n",
       "      <td>2.817038</td>\n",
       "      <td>1.784263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30494</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>1.145534</td>\n",
       "      <td>1.551736</td>\n",
       "      <td>1.492959</td>\n",
       "      <td>1.898079</td>\n",
       "      <td>1.955451</td>\n",
       "      <td>4.176614</td>\n",
       "      <td>3.136689</td>\n",
       "      <td>1.315667</td>\n",
       "      <td>1.551736</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098753</td>\n",
       "      <td>1.825846</td>\n",
       "      <td>2.090707</td>\n",
       "      <td>2.023895</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.805829</td>\n",
       "      <td>0.606214</td>\n",
       "      <td>0.715246</td>\n",
       "      <td>1.065588</td>\n",
       "      <td>0.298136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30495</th>\n",
       "      <td>HOBBIES_1_006_CA_1_evaluation</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.603343</td>\n",
       "      <td>0.930946</td>\n",
       "      <td>0.456842</td>\n",
       "      <td>0.699314</td>\n",
       "      <td>0.946712</td>\n",
       "      <td>0.506094</td>\n",
       "      <td>4.045746</td>\n",
       "      <td>0.603343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175462</td>\n",
       "      <td>0.151209</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>1.678147</td>\n",
       "      <td>0.270828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.056985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30496</th>\n",
       "      <td>HOBBIES_1_007_CA_1_evaluation</td>\n",
       "      <td>0.267318</td>\n",
       "      <td>0.192824</td>\n",
       "      <td>0.299227</td>\n",
       "      <td>0.305762</td>\n",
       "      <td>0.864935</td>\n",
       "      <td>0.269041</td>\n",
       "      <td>0.406385</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.192824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798840</td>\n",
       "      <td>0.576164</td>\n",
       "      <td>0.923692</td>\n",
       "      <td>0.940162</td>\n",
       "      <td>0.992437</td>\n",
       "      <td>0.470614</td>\n",
       "      <td>0.209512</td>\n",
       "      <td>0.315186</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30497</th>\n",
       "      <td>HOBBIES_1_008_CA_1_evaluation</td>\n",
       "      <td>11.685040</td>\n",
       "      <td>6.305268</td>\n",
       "      <td>10.346160</td>\n",
       "      <td>7.839515</td>\n",
       "      <td>8.388208</td>\n",
       "      <td>9.848098</td>\n",
       "      <td>14.043884</td>\n",
       "      <td>6.004989</td>\n",
       "      <td>6.305268</td>\n",
       "      <td>...</td>\n",
       "      <td>5.934118</td>\n",
       "      <td>1.479713</td>\n",
       "      <td>2.478768</td>\n",
       "      <td>16.999746</td>\n",
       "      <td>6.482188</td>\n",
       "      <td>2.025238</td>\n",
       "      <td>2.881044</td>\n",
       "      <td>11.714595</td>\n",
       "      <td>6.625737</td>\n",
       "      <td>6.525025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>HOBBIES_1_009_CA_1_evaluation</td>\n",
       "      <td>2.852529</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>2.048379</td>\n",
       "      <td>1.202897</td>\n",
       "      <td>1.091626</td>\n",
       "      <td>1.593028</td>\n",
       "      <td>1.620458</td>\n",
       "      <td>0.795144</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088094</td>\n",
       "      <td>2.788052</td>\n",
       "      <td>2.071830</td>\n",
       "      <td>2.115031</td>\n",
       "      <td>0.106516</td>\n",
       "      <td>0.469396</td>\n",
       "      <td>2.326511</td>\n",
       "      <td>3.429820</td>\n",
       "      <td>2.319166</td>\n",
       "      <td>2.301038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>HOBBIES_1_010_CA_1_evaluation</td>\n",
       "      <td>1.349583</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>0.587149</td>\n",
       "      <td>0.481595</td>\n",
       "      <td>0.569269</td>\n",
       "      <td>0.510581</td>\n",
       "      <td>0.869681</td>\n",
       "      <td>1.021150</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705148</td>\n",
       "      <td>1.006472</td>\n",
       "      <td>0.743819</td>\n",
       "      <td>0.810768</td>\n",
       "      <td>0.131817</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>0.505147</td>\n",
       "      <td>1.103369</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>1.579789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>HOBBIES_1_011_CA_1_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30501</th>\n",
       "      <td>HOBBIES_1_012_CA_1_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30502</th>\n",
       "      <td>HOBBIES_1_013_CA_1_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30503</th>\n",
       "      <td>HOBBIES_1_014_CA_1_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30504</th>\n",
       "      <td>HOBBIES_1_015_CA_1_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id         F1        F2         F3  \\\n",
       "30490  HOBBIES_1_001_CA_1_evaluation   0.060448  0.710953   0.000000   \n",
       "30491  HOBBIES_1_002_CA_1_evaluation   0.278447  0.325633   0.009176   \n",
       "30492  HOBBIES_1_003_CA_1_evaluation   0.454166  0.229238   0.252124   \n",
       "30493  HOBBIES_1_004_CA_1_evaluation   2.097975  1.589313   0.978691   \n",
       "30494  HOBBIES_1_005_CA_1_evaluation   1.145534  1.551736   1.492959   \n",
       "30495  HOBBIES_1_006_CA_1_evaluation   0.708417  0.603343   0.930946   \n",
       "30496  HOBBIES_1_007_CA_1_evaluation   0.267318  0.192824   0.299227   \n",
       "30497  HOBBIES_1_008_CA_1_evaluation  11.685040  6.305268  10.346160   \n",
       "30498  HOBBIES_1_009_CA_1_evaluation   2.852529  1.015794   2.048379   \n",
       "30499  HOBBIES_1_010_CA_1_evaluation   1.349583  0.715811   0.587149   \n",
       "30500  HOBBIES_1_011_CA_1_evaluation   0.000000  0.000000   0.000000   \n",
       "30501  HOBBIES_1_012_CA_1_evaluation   0.000000  0.000000   0.000000   \n",
       "30502  HOBBIES_1_013_CA_1_evaluation   0.000000  0.000000   0.000000   \n",
       "30503  HOBBIES_1_014_CA_1_evaluation   0.000000  0.000000   0.000000   \n",
       "30504  HOBBIES_1_015_CA_1_evaluation   0.000000  0.000000   0.000000   \n",
       "\n",
       "             F4        F5        F6         F7        F8        F9  ...  \\\n",
       "30490  0.223788  0.228602  0.168158   0.214708  0.000000  0.710953  ...   \n",
       "30491  0.367228  0.378045  0.432572   0.021260  0.010630  0.325633  ...   \n",
       "30492  0.273253  0.193736  0.666428   0.016962  1.498980  0.229238  ...   \n",
       "30493  0.857186  1.933128  3.185360   3.249015  1.696931  1.589313  ...   \n",
       "30494  1.898079  1.955451  4.176614   3.136689  1.315667  1.551736  ...   \n",
       "30495  0.456842  0.699314  0.946712   0.506094  4.045746  0.603343  ...   \n",
       "30496  0.305762  0.864935  0.269041   0.406385  0.004599  0.192824  ...   \n",
       "30497  7.839515  8.388208  9.848098  14.043884  6.004989  6.305268  ...   \n",
       "30498  1.202897  1.091626  1.593028   1.620458  0.795144  1.015794  ...   \n",
       "30499  0.481595  0.569269  0.510581   0.869681  1.021150  0.715811  ...   \n",
       "30500  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  ...   \n",
       "30501  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  ...   \n",
       "30502  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  ...   \n",
       "30503  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  ...   \n",
       "30504  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  ...   \n",
       "\n",
       "            F19       F20       F21        F22       F23       F24       F25  \\\n",
       "30490  0.747942  0.000000  0.000000   0.130675  0.381387  0.000000  0.931677   \n",
       "30491  0.567867  0.794892  0.420917   0.188256  0.244426  1.325752  0.162870   \n",
       "30492  0.384402  1.239972  0.005978   0.289158  0.000000  0.036501  0.018479   \n",
       "30493  1.364504  0.672822  2.513978   1.846013  1.789156  1.431149  1.015532   \n",
       "30494  1.098753  1.825846  2.090707   2.023895  0.905503  0.805829  0.606214   \n",
       "30495  0.175462  0.151209  0.735043   1.678147  0.270828  0.000000  0.057916   \n",
       "30496  0.000000  0.798840  0.576164   0.923692  0.940162  0.992437  0.470614   \n",
       "30497  5.934118  1.479713  2.478768  16.999746  6.482188  2.025238  2.881044   \n",
       "30498  2.088094  2.788052  2.071830   2.115031  0.106516  0.469396  2.326511   \n",
       "30499  0.705148  1.006472  0.743819   0.810768  0.131817  0.147788  0.505147   \n",
       "30500  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "30501  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "30502  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "30503  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "30504  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             F26       F27       F28  \n",
       "30490   1.003537  0.753696  2.091530  \n",
       "30491   0.247418  0.006402  0.623214  \n",
       "30492   0.473690  0.520014  0.222852  \n",
       "30493   1.690391  2.817038  1.784263  \n",
       "30494   0.715246  1.065588  0.298136  \n",
       "30495   0.056985  0.000000  0.000000  \n",
       "30496   0.209512  0.315186  0.000000  \n",
       "30497  11.714595  6.625737  6.525025  \n",
       "30498   3.429820  2.319166  2.301038  \n",
       "30499   1.103369  1.006675  1.579789  \n",
       "30500   0.000000  0.000000  0.000000  \n",
       "30501   0.000000  0.000000  0.000000  \n",
       "30502   0.000000  0.000000  0.000000  \n",
       "30503   0.000000  0.000000  0.000000  \n",
       "30504   0.000000  0.000000  0.000000  \n",
       "\n",
       "[15 rows x 29 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.iloc[30490:30505]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost + HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    'n_estimators':hp.quniform('n_estimators', 10, 2000, 25),\n",
    "    'learning_rate':hp.uniform('learning_rate', 0.00001, 1.0),\n",
    "    'max_depth':hp.quniform('x_max_depth', 8, 32, 1),\n",
    "    'min_child_weight':hp.quniform('x_min_child', 1, 10, 1),\n",
    "    'subsample':hp.uniform('x_subsample', 0.7, 1),\n",
    "    'gamma':hp.uniform('x_gamma', 0.1, 0.5),\n",
    "    'reg_lambda':hp.uniform('x_reg_lambda', 0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objetivo(space):\n",
    "    \n",
    "    modelo=xgb.XGBRegressor(\n",
    "        n_estimators=int(space['n_estimators']),\n",
    "        learning_rate=space['learning_rate'],\n",
    "        max_depth=int(space['max_depth']),\n",
    "        min_child_weight=space['min_child_weight'],\n",
    "        subsample=space['subsample'],\n",
    "        gamma=space['gamma'],\n",
    "        reg_lambda=space['reg_lambda'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "    \n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "    modelo.fit(X_train, y_train, eval_set=eval_set, eval_metric='rmse', verbose=False)\n",
    "    y_pred=modelo.predict(X_test)\n",
    "    rmse=MSE(y_test, y_pred)**0.5\n",
    "    \n",
    "    return {'loss':rmse, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def xgbmodel(i,ShowMSE=False, max_evals =5):\n",
    "    trials_reg=Trials()\n",
    "    \n",
    "    Xy=list_df_sell[i].copy()\n",
    "\n",
    "    #Stracting X_test\n",
    "    X_test=Xy.drop(columns=['day_sell'])[1913:]\n",
    "\n",
    "    #Remove Nones for all the sample  from X and y in the sell price\n",
    "    Xy.sell_price=Xy.sell_price.astype(float)\n",
    "    Xy=Xy[(Xy.sell_price>0) & (Xy.day_sell >=0)]\n",
    "\n",
    "    #Prepare X_train and y_train\n",
    "    X,y = Xy.drop(columns=['day_sell']), Xy.day_sell\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = TTS(X,y, test_size = 0.2, shuffle=False)\n",
    "    best=fmin(fn=objetivo, space=space, algo=tpe.suggest, max_evals=max_evals, trials=Trials())\n",
    "\n",
    "    #Train with complete data set and founded hyperparameters\n",
    "\n",
    "    modelo=xgb.XGBRegressor(\n",
    "        n_estimators=int(best['n_estimators']),\n",
    "        learning_rate=best['learning_rate'],\n",
    "        x_max_depth=int(best['x_max_depth']),\n",
    "        x_min_child=best['x_min_child'],\n",
    "        x_subsample=best['x_subsample'],\n",
    "        x_gamma=best['x_gamma'],\n",
    "        x_reg_lambda=best['x_reg_lambda'],\n",
    "        objective='reg:squarederror'\n",
    "        )\n",
    "\n",
    "    #Checking MSE\n",
    "    \n",
    "    if ShowMSE==True:\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred=modelo.predict(X_test)\n",
    "        print(MSE(y_test, y_pred))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    #Defining new X_train and y_train to train with the all dataset\n",
    "    Xy=list_df_sell[i].copy()\n",
    "\n",
    "    #Stracting X_test\n",
    "    X_test=Xy.drop(columns=['day_sell'])[1913:]\n",
    "    X_test.sell_price=X_test.sell_price.astype(float)\n",
    "\n",
    "    #Remove Nones for all the sample  from X and y in the sell price\n",
    "    Xy.sell_price=Xy.sell_price.astype(float)\n",
    "    Xy=Xy[(Xy.sell_price>0) & (Xy.day_sell >=0)]\n",
    "\n",
    "    #Prepare X_train and y_train\n",
    "    X,y = Xy.drop(columns=['day_sell']), Xy.day_sell\n",
    "    \n",
    "    \n",
    "    #Final Train\n",
    "    m=xgb.XGBRegressor()\n",
    "    m.fit(X_train,y_train)\n",
    "    y_pred=m.predict(X_test)\n",
    "    \n",
    "    y_pred=np.array(list((map(lambda x: 0 if x<0 else x,y_pred))))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.84s/it, best loss: 0.722018377467855]\n",
      "0.5619736255642137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3056742 , 0.23767391, 0.13566807, 0.12867454, 0.22564512,\n",
       "       0.18748155, 1.0384649 , 0.        , 0.07177058, 0.10478401,\n",
       "       0.83349669, 0.40323573, 0.31879982, 1.36095858, 0.01037201,\n",
       "       0.52990621, 1.70528877, 0.05309653, 0.01444811, 0.28841984,\n",
       "       0.18280241, 0.27844653, 0.32563314, 0.00917578, 0.36722845,\n",
       "       0.37804535, 0.4325718 , 0.02126017, 0.27844653, 0.32563314,\n",
       "       0.00917578, 0.36722845, 0.37804535, 0.4325718 , 0.02126017,\n",
       "       0.01063013, 0.32563314, 0.        , 0.12742424, 1.43955946,\n",
       "       0.        , 0.12698987, 0.51505345, 0.4972491 , 0.00436535,\n",
       "       0.0424206 , 0.56786722, 0.7948916 , 0.4209168 , 0.18825561,\n",
       "       0.2444258 , 1.32575178, 0.16287038, 0.24741837, 0.00640163,\n",
       "       0.62321407])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=xgbmodel(1,True)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
